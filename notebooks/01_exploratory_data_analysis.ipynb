{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modular Exploratory Data Analysis of News Articles\n",
    "\n",
    "This notebook demonstrates the use of our custom utility classes for analyzing news articles data.\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to Python path\n",
    "\n",
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import our utility classes\n",
    "from src.utils.text_analyzer import TextAnalyzer\n",
    "from src.utils.time_analyzer import TimeAnalyzer\n",
    "from src.utils.publisher_analyzer import PublisherAnalyzer\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Analyzers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize our analyzer classes\n",
    "text_analyzer = TextAnalyzer()\n",
    "time_analyzer = TimeAnalyzer(date_column='publication_date')\n",
    "publisher_analyzer = PublisherAnalyzer(publisher_column='publisher')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "# Replace 'your_data.csv' with actual data file\n",
    "df = pd.read_csv('../data/your_data.csv')\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nSample Data:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text Analysis\n",
    "\n",
    "Analyze the textual content of headlines using our TextAnalyzer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get basic text statistics\n",
    "text_stats = text_analyzer.get_text_statistics(df['headline'])\n",
    "print(\"Text Statistics:\")\n",
    "for key, value in text_stats.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Extract and display common words\n",
    "common_words = text_analyzer.extract_common_words(df['headline'], top_n=15)\n",
    "print(\"\\nMost Common Words:\")\n",
    "for word, count in common_words:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# Generate and display word cloud\n",
    "plt.figure(figsize=(15, 8))\n",
    "wordcloud = text_analyzer.generate_wordcloud(df['headline'])\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Headlines')\n",
    "plt.show()\n",
    "\n",
    "# Perform topic modeling\n",
    "lda_model, corpus, dictionary = text_analyzer.perform_topic_modeling(df['headline'], num_topics=5)\n",
    "print(\"\\nTop Topics:\")\n",
    "for idx, topic in lda_model.print_topics():\n",
    "    print(f\"Topic #{idx + 1}:\")\n",
    "    print(topic, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time Series Analysis\n",
    "\n",
    "Analyze temporal patterns using our TimeAnalyzer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get publication patterns\n",
    "time_patterns = time_analyzer.get_publication_patterns(df)\n",
    "\n",
    "# Plot daily publication counts\n",
    "plt.figure(figsize=(15, 6))\n",
    "time_patterns['daily_counts'].plot()\n",
    "plt.title('Daily Publication Counts')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot weekly patterns\n",
    "plt.figure(figsize=(10, 6))\n",
    "time_patterns['weekly_counts'].plot(kind='bar')\n",
    "plt.title('Articles by Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create publication heatmap\n",
    "time_analyzer.create_heatmap(df)\n",
    "plt.show()\n",
    "\n",
    "# Analyze temporal density\n",
    "density_metrics = time_analyzer.analyze_temporal_density(df)\n",
    "print(\"\\nTemporal Density Metrics:\")\n",
    "for key, value in density_metrics.items():\n",
    "    if isinstance(value, pd.Timedelta):\n",
    "        print(f\"{key}: {value.total_seconds() / 3600:.2f} hours\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Publisher Analysis\n",
    "\n",
    "Analyze publisher patterns using our PublisherAnalyzer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get publisher statistics\n",
    "pub_stats = publisher_analyzer.get_publisher_statistics(df)\n",
    "print(\"Publisher Statistics:\")\n",
    "for key, value in pub_stats.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"\\n{key}:\")\n",
    "        for k, v in value.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# Analyze and plot publisher domains\n",
    "domain_counts = publisher_analyzer.analyze_publisher_domains(df)\n",
    "print(\"\\nTop Publishing Domains:\")\n",
    "print(domain_counts.head(10))\n",
    "\n",
    "# Plot top publishers\n",
    "publisher_analyzer.plot_top_publishers(df)\n",
    "plt.show()\n",
    "\n",
    "# Analyze publisher patterns\n",
    "pub_patterns = publisher_analyzer.analyze_publisher_patterns(df)\n",
    "\n",
    "# Create heatmap of publisher patterns\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(pub_patterns, cmap='YlOrRd', annot=True, fmt='.0f')\n",
    "plt.title('Publishing Patterns by Publisher and Hour')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Publisher')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Findings\n",
    "\n",
    "Use this section to summarize key findings from your analysis:\n",
    "\n",
    "1. Text Analysis:\n",
    "   - Average headline length and common topics\n",
    "   - Most frequent keywords and their implications\n",
    "\n",
    "2. Time Analysis:\n",
    "   - Peak publishing times\n",
    "   - Weekly patterns\n",
    "   - Any notable temporal trends\n",
    "\n",
    "3. Publisher Analysis:\n",
    "   - Most active publishers\n",
    "   - Publishing patterns\n",
    "   - Domain distribution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
