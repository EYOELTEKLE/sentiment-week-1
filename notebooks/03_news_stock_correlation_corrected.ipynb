{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3: Correlation Analysis between News Sentiment and Multiple Stocks\n",
        "\n",
        "This notebook analyzes the correlation between news sentiment and multiple stock price movements.\n",
        "It attempts to use stock-specific news sentiment if available, otherwise, it can be adapted\n",
        "to use general market sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import scipy.stats as stats\n",
        "from typing import Dict, List, Tuple, Optional, Union\n",
        "\n",
        "\n",
        "\n",
        "# Import functions from utility modules\n",
        "from src.utils.sentiment_analysis import analyze_headlines, aggregate_daily_sentiment,plot_sentiment_returns_timeseries\n",
        "from src.utils.correlation_analysis import calculate_returns, align_sentiment_returns, calculate_correlation_metrics, analyze_lagged_correlations\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams['figure.figsize'] = [12, 6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load news data\n",
        "NEWS_FILE_PATH = '../data/raw_analyst_ratings.csv/raw_analyst_ratings.csv'\n",
        "try:\n",
        "    news_df_raw = pd.read_csv(NEWS_FILE_PATH)\n",
        "    print(\"Raw news data shape:\", news_df_raw.shape)\n",
        "    print(\"News data columns:\", news_df_raw.columns)\n",
        "    news_df_raw.head()\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: News data file not found at {NEWS_FILE_PATH}\")\n",
        "    news_df_raw = pd.DataFrame() # Create empty df to avoid later errors if user wants to proceed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load stock data for all companies\n",
        "STOCK_DATA_DIR = Path('../data/yfinance_data')\n",
        "stock_dfs = {}\n",
        "if STOCK_DATA_DIR.exists() and STOCK_DATA_DIR.is_dir():\n",
        "    stock_files = list(STOCK_DATA_DIR.glob('*.csv'))\n",
        "    if not stock_files:\n",
        "        print(f\"No CSV files found in {STOCK_DATA_DIR}\")\n",
        "    for file in stock_files:\n",
        "        try:\n",
        "            symbol = file.stem.upper()  # Get filename without extension, use upper for consistency\n",
        "            df = pd.read_csv(file)\n",
        "            df['Date'] = pd.to_datetime(df['Date'])\n",
        "            # Ensure 'Close' column exists\n",
        "            if 'Close' not in df.columns:\n",
        "                print(f\"Warning: 'Close' column not found in {file.name}. Skipping this stock.\")\n",
        "                continue\n",
        "            stock_dfs[symbol] = df\n",
        "            print(f\"Loaded {symbol} data with shape: {df.shape}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading or processing stock file {file.name}: {e}\")\n",
        "else:\n",
        "    print(f\"Error: Stock data directory not found at {STOCK_DATA_DIR}\")\n",
        "\n",
        "if stock_dfs:\n",
        "    list(stock_dfs.values())[0].head()\n",
        "else:\n",
        "    print(\"No stock data loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Sentiment Analysis of News\n",
        "We will perform sentiment analysis on headlines. If the news data contains a 'stock' or 'symbol' column,\n",
        "we will attempt to perform stock-specific sentiment aggregation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_sentiment_results = pd.DataFrame()\n",
        "daily_sentiment_aggregated = pd.DataFrame()\n",
        "\n",
        "# Standardize potential stock symbol column names in news_df\n",
        "# Common names: 'stock', 'ticker', 'symbol'\n",
        "NEWS_SYMBOL_COL = None\n",
        "potential_symbol_cols = ['stock', 'ticker', 'symbol']\n",
        "for col in potential_symbol_cols:\n",
        "    if col in news_df_raw.columns:\n",
        "        NEWS_SYMBOL_COL = col\n",
        "        print(f\"Found stock symbol column: '{col}'\")\n",
        "        break\n",
        "\n",
        "if not news_df_raw.empty:\n",
        "    if 'headline' in news_df_raw.columns:\n",
        "        # Analyze sentiment for each headline\n",
        "        print(\"Analyzing sentiment for news headlines...\")\n",
        "        sentiment_scores_df = analyze_headlines(news_df_raw['headline'])\n",
        "        \n",
        "        # Add date column from news data\n",
        "        if 'date' in news_df_raw.columns:\n",
        "            sentiment_scores_df['date'] = pd.to_datetime(news_df_raw['date'], errors='coerce')\n",
        "            sentiment_scores_df.dropna(subset=['date'], inplace=True) # Remove rows where date couldn't be parsed\n",
        "        \n",
        "        # Add company symbols if available and identified\n",
        "        if NEWS_SYMBOL_COL:\n",
        "            sentiment_scores_df[NEWS_SYMBOL_COL] = news_df_raw[NEWS_SYMBOL_COL].str.upper() # Standardize to uppercase\n",
        "        \n",
        "        # Store the full sentiment results\n",
        "        all_sentiment_results = sentiment_scores_df\n",
        "        \n",
        "        # Aggregate sentiment by date (and symbol if available)\n",
        "        if 'date' in sentiment_scores_df.columns:\n",
        "            print(\"Aggregating daily sentiment...\")\n",
        "            daily_sentiment_aggregated = aggregate_daily_sentiment(\n",
        "                sentiment_scores_df, 'date', NEWS_SYMBOL_COL\n",
        "            )\n",
        "            print(f\"Daily sentiment shape: {daily_sentiment_aggregated.shape}\")\n",
        "            daily_sentiment_aggregated.head()\n",
        "        else:\n",
        "            print(\"Warning: No date column found in news data. Cannot aggregate by date.\")\n",
        "        \n",
        "        # Visualize sentiment distribution\n",
        "        if not all_sentiment_results.empty:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            sns.histplot(data=all_sentiment_results, x='polarity', bins=50, kde=True)\n",
        "            plt.title('Distribution of Overall Sentiment Polarity in News')\n",
        "            plt.xlabel('Polarity Score')\n",
        "            plt.show()\n",
        "        \n",
        "        if not daily_sentiment_aggregated.empty:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(daily_sentiment_aggregated['date'], daily_sentiment_aggregated['mean_polarity'])\n",
        "            plt.title('Daily Average Sentiment Polarity Over Time')\n",
        "            plt.xlabel('Date')\n",
        "            plt.ylabel('Mean Polarity')\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "    else:\n",
        "        print(\"News data is empty. Skipping sentiment analysis.\")\n",
        "else:\n",
        "    print(\"Error: 'headline' column not found in news_df_raw. Cannot perform sentiment analysis.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Calculate Stock Returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stock_returns = {}\n",
        "if stock_dfs:\n",
        "    for symbol, df in stock_dfs.items():\n",
        "        try:\n",
        "            # Calculate daily returns\n",
        "            returns = calculate_returns(df['Close'])\n",
        "            \n",
        "            # Create a DataFrame with date and returns\n",
        "            returns_df = pd.DataFrame({\n",
        "                'Date': df['Date'],\n",
        "                'Close': df['Close'],\n",
        "                'Returns': returns\n",
        "            }).set_index('Date')\n",
        "            \n",
        "            # Store in dictionary\n",
        "            stock_returns[symbol] = returns_df\n",
        "            \n",
        "            plot_sentiment_returns_timeseries()\n",
        "            print(f\"Calculated returns for {symbol}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating returns for {symbol}: {e}\")\n",
        "    \n",
        "    # Show example of returns for one stock\n",
        "    if stock_returns:\n",
        "        first_symbol = list(stock_returns.keys())[0]\n",
        "        print(f\"\\nExample returns for {first_symbol}:\")\n",
        "        stock_returns[first_symbol].head()\n",
        "else:\n",
        "    print(\"No stock data loaded to calculate returns.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Correlation Analysis for Each Stock\n",
        "We will now correlate the daily sentiment scores with stock returns.\n",
        "If stock-specific sentiment is available, it will be used for the respective stock.\n",
        "Otherwise, a general sentiment (if calculated) might be used, or the stock skipped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "correlation_results = {}\n",
        "aligned_data_cache = {} # To store aligned data for later use (e.g., plotting)\n",
        "\n",
        "if stock_returns and not daily_sentiment_aggregated.empty:\n",
        "    for symbol, returns_df in stock_returns.items():\n",
        "        print(f\"\\nAnalyzing correlation for {symbol}...\")\n",
        "        \n",
        "        # Get sentiment data for this symbol if available\n",
        "        if NEWS_SYMBOL_COL and NEWS_SYMBOL_COL in daily_sentiment_aggregated.columns:\n",
        "            # Filter sentiment for this specific stock\n",
        "            symbol_sentiment = daily_sentiment_aggregated[daily_sentiment_aggregated[NEWS_SYMBOL_COL] == symbol]\n",
        "            if len(symbol_sentiment) > 1:  # Need at least 2 points for correlation\n",
        "                print(f\"Found {len(symbol_sentiment)} days with sentiment data for {symbol}\")\n",
        "                sentiment_to_use = symbol_sentiment\n",
        "            else:\n",
        "                print(f\"Insufficient sentiment data for {symbol} (only {len(symbol_sentiment)} days). Skipping.\")\n",
        "                correlation_results[symbol] = {\n",
        "                    'pearson_correlation': None, 'pearson_p_value': None,\n",
        "                    'spearman_correlation': None, 'spearman_p_value': None,\n",
        "                    'n_observations': len(symbol_sentiment),\n",
        "                    'error': 'Insufficient sentiment data'\n",
        "                }\n",
        "                continue\n",
        "        else:\n",
        "            # Use general sentiment (all headlines)\n",
        "            print(f\"No stock-specific sentiment found. Using general market sentiment for {symbol}.\")\n",
        "            sentiment_to_use = daily_sentiment_aggregated\n",
        "        \n",
        "        try:\n",
        "            # Align sentiment and returns data by date\n",
        "            aligned_sentiment, aligned_returns = align_sentiment_returns(\n",
        "                sentiment_to_use, \n",
        "                returns_df.reset_index(), \n",
        "                'date' if 'date' in sentiment_to_use.columns else daily_sentiment_aggregated.columns[0],\n",
        "                'Date'\n",
        "            )\n",
        "            \n",
        "            if len(aligned_sentiment) >= 2:  # Need at least 2 points for correlation\n",
        "                print(f\"Found {len(aligned_sentiment)} days with both sentiment and returns data\")\n",
        "                \n",
        "                # Store aligned data for later use\n",
        "                aligned_data_cache[symbol] = {\n",
        "                    'sentiment': aligned_sentiment,\n",
        "                    'returns': aligned_returns\n",
        "                }\n",
        "                \n",
        "                # Calculate correlation metrics\n",
        "                metrics = calculate_correlation_metrics(\n",
        "                    aligned_sentiment['mean_polarity'],\n",
        "                    aligned_returns['Returns']\n",
        "                )\n",
        "                \n",
        "                correlation_results[symbol] = metrics\n",
        "                \n",
        "                # Print correlation results\n",
        "                print(f\"Pearson correlation: {metrics['pearson_correlation']:.4f} (p-value: {metrics['pearson_p_value']:.4f})\")\n",
        "                print(f\"Spearman correlation: {metrics['spearman_correlation']:.4f} (p-value: {metrics['spearman_p_value']:.4f})\")\n",
        "                \n",
        "                # Analyze lagged correlations\n",
        "                print(\"\\nAnalyzing lagged correlations...\")\n",
        "                lagged_corr = analyze_lagged_correlations(\n",
        "                    aligned_sentiment['mean_polarity'],\n",
        "                    aligned_returns['Returns'],\n",
        "                    max_lag=5\n",
        "                )\n",
        "                \n",
        "                if not lagged_corr.empty:\n",
        "                    # Plot lagged correlations\n",
        "                    plt.figure(figsize=(12, 6))\n",
        "                    plt.bar(lagged_corr['lag'], lagged_corr['pearson_correlation'])\n",
        "                    plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
        "                    plt.title(f'Lagged Correlations for {symbol} (Sentiment vs. Returns)')\n",
        "                    plt.xlabel('Lag (days): negative = sentiment leads, positive = returns lead')\n",
        "                    plt.ylabel('Pearson Correlation')\n",
        "                    \n",
        "                    # Add N values to the plot\n",
        "                    for i, row in lagged_corr.iterrows():\n",
        "                        plt.text(row['lag'], row['pearson_correlation'], \n",
        "                                f\"N={row['n_observations']}\", \n",
        "                                ha='center', va='bottom' if row['pearson_correlation'] > 0 else 'top',\n",
        "                                fontsize=8)\n",
        "                    \n",
        "                    plt.grid(True)\n",
        "                    plt.show()\n",
        "                else:\n",
        "                    print(\"Could not calculate lagged correlations due to insufficient data\")\n",
        "            else:\n",
        "                print(f\"Insufficient aligned data for {symbol} (only {len(aligned_sentiment)} days). Skipping correlation analysis.\")\n",
        "                correlation_results[symbol] = {\n",
        "                    'pearson_correlation': None, 'pearson_p_value': None,\n",
        "                    'spearman_correlation': None, 'spearman_p_value': None,\n",
        "                    'n_observations': len(aligned_sentiment),\n",
        "                    'error': 'Insufficient aligned data'\n",
        "                }\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing correlation for {symbol}: {str(e)}\")\n",
        "            correlation_results[symbol] = {\n",
        "                'pearson_correlation': None, 'pearson_p_value': None,\n",
        "                'spearman_correlation': None, 'spearman_p_value': None,\n",
        "                'error': str(e)\n",
        "            }\n",
        "else:\n",
        "    print(\"Cannot perform correlation analysis: missing sentiment data or stock returns.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualize Correlation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter plot of sentiment vs returns for each stock with sufficient data\n",
        "if aligned_data_cache:\n",
        "    for symbol, data in aligned_data_cache.items():\n",
        "        if len(data['sentiment']) >= 5:  # Only plot if we have enough data points\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.scatter(data['sentiment']['mean_polarity'], data['returns']['Returns'], alpha=0.7)\n",
        "            \n",
        "            # Add regression line if we have valid correlation\n",
        "            if symbol in correlation_results and correlation_results[symbol].get('valid', False):\n",
        "                x = data['sentiment']['mean_polarity']\n",
        "                y = data['returns']['Returns']\n",
        "                \n",
        "                # Simple linear regression\n",
        "                try:\n",
        "                    m, b = np.polyfit(x, y, 1)\n",
        "                    plt.plot(x, m*x + b, 'r-', alpha=0.7)\n",
        "                    \n",
        "                    # Add correlation info to plot\n",
        "                    corr = correlation_results[symbol]['pearson_correlation']\n",
        "                    p_val = correlation_results[symbol]['pearson_p_value']\n",
        "                    plt.text(0.05, 0.95, f\"Correlation: {corr:.4f}\\np-value: {p_val:.4f}\", \n",
        "                            transform=plt.gca().transAxes, fontsize=12,\n",
        "                            verticalalignment='top', bbox=dict(boxstyle='round', alpha=0.1))\n",
        "                except Exception as e:\n",
        "                    print(f\"Could not add regression line for {symbol}: {e}\")\n",
        "            \n",
        "            plt.title(f'Sentiment vs. Returns for {symbol}')\n",
        "            plt.xlabel('Mean Sentiment Polarity')\n",
        "            plt.ylabel('Returns')\n",
        "            plt.grid(True)\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary of Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a summary table of correlation results\n",
        "if correlation_results:\n",
        "    summary_data = []\n",
        "    \n",
        "    for symbol, metrics in correlation_results.items():\n",
        "        if metrics.get('valid', True) and metrics.get('pearson_correlation') is not None:\n",
        "            summary_data.append({\n",
        "                'Symbol': symbol,\n",
        "                'Pearson Correlation': metrics['pearson_correlation'],\n",
        "                'Pearson p-value': metrics['pearson_p_value'],\n",
        "                'Spearman Correlation': metrics['spearman_correlation'],\n",
        "                'Spearman p-value': metrics['spearman_p_value'],\n",
        "                'Observations': metrics.get('n_observations', 0),\n",
        "                'Significant at 5% (Pearson)': metrics['pearson_p_value'] < 0.05,\n",
        "                'Notes': 'Valid correlation'\n",
        "            })\n",
        "        else: # Include symbols for which analysis failed or was skipped, with reasons\n",
        "             summary_data.append({\n",
        "                'Symbol': symbol,\n",
        "                'Pearson Correlation': None, 'Pearson p-value': None,\n",
        "                'Spearman Correlation': None, 'Spearman p-value': None,\n",
        "                'Observations': metrics.get('n_observations', 0),\n",
        "                'Significant at 5% (Pearson)': False,\n",
        "                'Notes': metrics.get('error', 'Skipped or failed')\n",
        "            })\n",
        "\n",
        "\n",
        "    if summary_data:\n",
        "        summary_df = pd.DataFrame(summary_data)\n",
        "        # Attempt to sort, handle cases where correlation might be None\n",
        "        try:\n",
        "            summary_df = summary_df.sort_values('Pearson Correlation', ascending=False, na_position='last')\n",
        "        except TypeError:\n",
        "            print(\"Note: Could not sort summary by Pearson Correlation due to mixed types (likely None values).\")\n",
        "        \n",
        "        print(\"\\nComprehensive Summary of Correlation Analysis:\")\n",
        "        print(summary_df)\n",
        "    else:\n",
        "        print(\"No data to generate summary insights.\")\n",
        "else:\n",
        "    print(\"No correlation results to summarize.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
